{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9444027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48979309",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"/Users/nkitharamisetty/Desktop/assignment3/train\"\n",
    "path_test = \"/Users/nkitharamisetty/Desktop/assignment3/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3606ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Word Count: 9185\n"
     ]
    }
   ],
   "source": [
    "total_size = 0\n",
    "size_spam = 0\n",
    "size_ham = 0\n",
    "path = os.listdir(path_train)\n",
    "spam_word_count={}\n",
    "ham_word_count = {}\n",
    "total_word_count = {}\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue\n",
    "    y = os.listdir(path_train+\"//\" + i)\n",
    "\n",
    "    if i==\"ham\":\n",
    "        for j in y:\n",
    "            total_size = total_size + 1\n",
    "            size_ham = size_ham + 1\n",
    "            f = path_train+\"//\"+ i + \"//\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in ham_word_count and word.isalpha():\n",
    "                    ham_word_count[word] = 1\n",
    "                    total_word_count[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    ham_word_count[word] =  ham_word_count[word]+1\n",
    "                    total_word_count[word] = total_word_count[word]+1\n",
    "\n",
    "    else:\n",
    "        for j in y:\n",
    "            total_size += 1\n",
    "            size_spam += 1\n",
    "            f = path_train+\"//\"+ i + \"//\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in spam_word_count and word.isalpha():\n",
    "                    spam_word_count[word] = 1\n",
    "                    total_word_count[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    spam_word_count[word] += 1\n",
    "                    total_word_count[word] += 1\n",
    "print(\"Total Word Count:\",len(total_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00053a",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2bacbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 463\n",
      "Number of spam files: 123\n",
      "Number of ham files: 340\n",
      "Accuracy 0.9219214600635702\n"
     ]
    }
   ],
   "source": [
    "totalwords_spam = sum(spam_word_count.values())\n",
    "totalwords_ham = sum(ham_word_count.values())\n",
    "length = len(total_word_count)\n",
    "count_spam = 0\n",
    "count_ham = 0\n",
    "cst = 0\n",
    "cht = 0\n",
    "size_test = 0\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue\n",
    "    y = os.listdir(path_test+\"//\"+ i)\n",
    "    for j in y:\n",
    "        test_sham = {}\n",
    "        size_test = size_test + 1\n",
    "        f = path_test+\"//\"+ i + \"//\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in test_sham and word.isalpha():\n",
    "                test_sham[word] = 1\n",
    "            elif word.isalpha():\n",
    "                test_sham[word] = test_sham[word] + 1\n",
    "        prob_spam = math.log(size_spam/total_size)\n",
    "        prob_ham = math.log(size_ham/total_size)\n",
    "        for k in test_sham:\n",
    "            if spam_word_count.get(k) != None:\n",
    "                prob_spam = prob_spam + math.log((spam_word_count.get(k)+1)/((totalwords_spam)+(length)))\n",
    "            else:\n",
    "                prob_spam = prob_spam + math.log((1)/((totalwords_spam)+(length)))\n",
    "            if ham_word_count.get(k) != None:\n",
    "                prob_ham = prob_ham + math.log((ham_word_count.get(k)+1)/((totalwords_ham)+(length)))\n",
    "            else:\n",
    "                prob_ham = prob_ham + math.log((1)/((totalwords_ham)+(length)))\n",
    "\n",
    "            if prob_spam > prob_ham:\n",
    "                count_spam = count_spam + 1\n",
    "                if i==\"spam\":\n",
    "                    cst = cst + 1\n",
    "            elif prob_ham > prob_spam:\n",
    "                count_ham = count_ham + 1\n",
    "                if i==\"ham\":\n",
    "                    cht = cht + 1\n",
    "print(\"Number of files:\",total_size)\n",
    "print(\"Number of spam files:\",size_spam)\n",
    "print(\"Number of ham files:\",size_ham)\n",
    "print(\"Accuracy\",(cst+cht)/(count_spam+count_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00b217",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "158459a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5\n",
    "lambd = 0.01\n",
    "eta = 0.01\n",
    "log_total_word_count = list(total_word_count.keys())\n",
    "mat = np.zeros((total_size,len(log_total_word_count)+1))\n",
    "z = 0\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue\n",
    "    y = os.listdir(path_train+\"//\"+ i)\n",
    "    for j in y:\n",
    "        log_word_count = {}\n",
    "        f = path_train+\"//\"+ i + \"//\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in log_word_count and word.isalpha():\n",
    "                log_word_count[word] = 1\n",
    "            elif word.isalpha():\n",
    "                log_word_count[word] = log_word_count[word]+ 1\n",
    "        for k in log_word_count:\n",
    "\n",
    "            mat[z][log_total_word_count.index(k)] = log_word_count[k]\n",
    "        if i==\"spam\":\n",
    "            mat[z][len(log_total_word_count)] = 1\n",
    "        z = z + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09607f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(w,x):\n",
    "    s = 0\n",
    "    for i in range(len(x)):\n",
    "        s = s + (w[i]*x[i])\n",
    "    try:\n",
    "        p = math.exp(w[0]+s)/(1 + math.exp(w[0]+s))\n",
    "    except:\n",
    "        p = 1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cec6d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = np.ones(len(total_word_count)+1)\n",
    "w = np.ones(len(total_word_count)+1)\n",
    "probab = np.ones(mat.shape[0])\n",
    "for k in range(iterations):\n",
    "    w = w_new.copy()\n",
    "    w_new = np.ones(len(total_word_count)+1)\n",
    "    for l in range(mat.shape[0]):\n",
    "        probab[l] = prob(w,mat[l])\n",
    "    for i in range(len(w)):\n",
    "        temp = 0\n",
    "        for j in range(mat.shape[0]):\n",
    "            temp = temp + mat[j][i]*((mat[j][mat.shape[1]-1])-probab[j])\n",
    "        w_new[i] = w[i]+ (lambd * temp) - (lambd*eta*w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5213105",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = np.zeros((size_test,len(log_total_word_count)+1))\n",
    "z = 0\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue  \n",
    "    y = os.listdir(path_test+\"//\"+ i)\n",
    "    for j in y:\n",
    "        log_word_count = {}\n",
    "        f = path_test+\"//\"+ i + \"//\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in log_word_count and word.isalpha():\n",
    "                log_word_count[word] = 1\n",
    "            elif word.isalpha():\n",
    "                log_word_count[word] += 1\n",
    "        for k in log_word_count:\n",
    "            if k in log_total_word_count:\n",
    "                mat_test[z][log_total_word_count.index(k)] = log_word_count[k]\n",
    "        if i==\"spam\":\n",
    "            mat_test[z][len(log_total_word_count)] = 1\n",
    "        z = z + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46e347e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations:10\n",
      "Accuracy: 0.8263598326359832\n"
     ]
    }
   ],
   "source": [
    "th = 0\n",
    "ts = 0\n",
    "tt = 0\n",
    "for i in range(mat_test.shape[0]):\n",
    "    s = 0\n",
    "    for j in range(mat_test.shape[1]-1):\n",
    "        s = s + (w_new[j]*mat_test[i][j])\n",
    "    s = s + w[0]\n",
    "    tt += 1\n",
    "    if mat_test[i][len(log_total_word_count)]==1 and s>0:\n",
    "        ts += 1\n",
    "    elif mat_test[i][len(log_total_word_count)]==0 and s<0:\n",
    "        th += 1\n",
    "print(\"Number of Iterations:\"+ str(iterations))\n",
    "print(\"Accuracy:\",(ts+th)/tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59d21f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\",\n",
    "             \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\",\n",
    "             \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\",\n",
    "             \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\",\n",
    "             \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\",\n",
    "             \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\n",
    "             \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\",\n",
    "             \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\",\n",
    "             \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\",\n",
    "             \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\",\n",
    "             \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\",\n",
    "             \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\",\n",
    "             \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\",\n",
    "             \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\",\n",
    "             \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\",\n",
    "             \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27572c",
   "metadata": {},
   "source": [
    "Naive Bayes with stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71b71b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Word Count: 9067\n"
     ]
    }
   ],
   "source": [
    "path = os.listdir(path_train)\n",
    "spam_word_count={}\n",
    "ham_word_count = {}\n",
    "total_word_count = {}\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue  \n",
    "    y = os.listdir(path_train+\"//\"+ i)\n",
    "    if i==\"spam\":\n",
    "        for j in y:\n",
    "            f = path_train+\"//\"+ i + \"//\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in stopWords:\n",
    "                    if word not in spam_word_count and word.isalpha():\n",
    "                        spam_word_count[word] = 1\n",
    "                        total_word_count[word] = 1\n",
    "                    elif word.isalpha():\n",
    "                        spam_word_count[word] += 1\n",
    "                        total_word_count[word] += 1\n",
    "    else:\n",
    "        for j in y:\n",
    "            f = path_train+\"//\"+ i + \"//\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in stopWords:\n",
    "                    if word not in ham_word_count and word.isalpha():\n",
    "                        ham_word_count[word] = 1\n",
    "                        total_word_count[word] = 1\n",
    "                    elif word.isalpha():\n",
    "                        ham_word_count[word] += 1\n",
    "                        total_word_count[word] += 1\n",
    "\n",
    "print(\"Total Word Count:\",len(total_word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41aab8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 463\n",
      "Number of spam files: 123\n",
      "Number of ham files: 340\n",
      "Accuracy 0.9232201023731968\n"
     ]
    }
   ],
   "source": [
    "totalwords_spam = sum(spam_word_count.values())\n",
    "totalwords_ham = sum(ham_word_count.values())\n",
    "length = len(total_word_count)\n",
    "count_spam = 0\n",
    "count_ham = 0\n",
    "cst = 0\n",
    "cht = 0\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue  \n",
    "    y = os.listdir(path_test+\"//\"+ i)\n",
    "    for j in y:\n",
    "        test_sh = {}\n",
    "        f = path_test+\"//\"+ i + \"//\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in stopWords:\n",
    "                if word not in test_sh and word.isalpha():\n",
    "                    test_sh[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    test_sh[word] += 1\n",
    "        prob_spam = math.log(size_spam/total_size)\n",
    "        prob_ham = math.log(size_ham/total_size)\n",
    "    \n",
    "        for k in test_sh:\n",
    "            if spam_word_count.get(k) != None:\n",
    "                prob_spam = prob_spam + math.log((spam_word_count.get(k)+1)/((totalwords_spam)+(length)))\n",
    "            else:\n",
    "                prob_spam = prob_spam + math.log((1)/((totalwords_spam)+(length)))\n",
    "            if ham_word_count.get(k) != None:\n",
    "                prob_ham = prob_ham + math.log((ham_word_count.get(k)+1)/((totalwords_ham)+(length)))\n",
    "            else:\n",
    "                prob_ham = prob_ham + math.log((1)/((totalwords_ham)+(length)))\n",
    "\n",
    "            if prob_spam > prob_ham:\n",
    "                count_spam = count_spam + 1\n",
    "                if i==\"spam\":\n",
    "                    cst = cst + 1\n",
    "            elif prob_ham > prob_spam:\n",
    "                count_ham = count_ham + 1\n",
    "                if i==\"ham\":\n",
    "                    cht = cht + 1\n",
    "print(\"Number of files:\",total_size)\n",
    "print(\"Number of spam files:\",size_spam)\n",
    "print(\"Number of ham files:\",size_ham)\n",
    "print(\"Accuracy\",(cst+cht)/(count_spam+count_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3fd51b",
   "metadata": {},
   "source": [
    " Logistic Regression with stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebba8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_total_word_count = list(total_word_count.keys())\n",
    "mat = np.zeros((total_size,len(log_total_word_count)+1))\n",
    "z = 0\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue  \n",
    "    y = os.listdir(path_train+\"//\"+ i)\n",
    "    for j in y:\n",
    "        log_word_count = {}\n",
    "        f = path_train+\"//\"+ i + \"//\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in stopWords:\n",
    "                if word not in log_word_count and word.isalpha():\n",
    "                    log_word_count[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    log_word_count[word] += 1\n",
    "        for k in log_word_count:\n",
    "            mat[z][log_total_word_count.index(k)] = log_word_count[k]\n",
    "        if i==\"spam\":\n",
    "            mat[z][len(log_total_word_count)] = 1\n",
    "        z = z + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd26b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = np.ones(len(total_word_count)+1)\n",
    "w = np.ones(len(total_word_count)+1)\n",
    "for k in range(iterations):\n",
    "    w = w_new.copy()\n",
    "    w_new = np.ones(len(total_word_count)+1)\n",
    "    for l in range(mat.shape[0]):\n",
    "        probab[l] = prob(w,mat[l])\n",
    "    for i in range(len(w)):\n",
    "        temp = 0\n",
    "        for j in range(mat.shape[0]):\n",
    "            temp = temp + mat[j][i]*((mat[j][mat.shape[1]-1])-probab[j])\n",
    "        w_new[i] = w[i]+ (lambd * temp) - (lambd*eta*w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06e0938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = np.zeros((size_test,len(log_total_word_count)+1))\n",
    "z = 0\n",
    "for i in path:\n",
    "    if i == '.DS_Store':\n",
    "         continue  \n",
    "    y = os.listdir(path_test+\"//\"+ i)\n",
    "    for j in y:\n",
    "        log_word_count = {}\n",
    "        f = path_test+\"//\"+ i + \"//\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in stopWords:\n",
    "                if word not in log_word_count and word.isalpha():\n",
    "                    log_word_count[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    log_word_count[word] += 1\n",
    "        for k in log_word_count:\n",
    "            if k in log_total_word_count:\n",
    "                mat_test[z][log_total_word_count.index(k)] = log_word_count[k]\n",
    "        if i==\"spam\":\n",
    "            mat_test[z][len(log_total_word_count)] = 1\n",
    "        z = z + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac7f97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 5\n",
      "Accuracy: 0.8305439330543933\n"
     ]
    }
   ],
   "source": [
    "th = 0\n",
    "ts = 0\n",
    "tt = 0\n",
    "\n",
    "for i in range(mat_test.shape[0]):\n",
    "    s = 0\n",
    "    for j in range(mat_test.shape[1]-1):\n",
    "        s = s + (w_new[j]*mat_test[i][j])\n",
    "    s = s + w[0]\n",
    "    tt += 1\n",
    "    if mat_test[i][len(log_total_word_count)]==1 and s>0:\n",
    "        ts += 1\n",
    "    elif mat_test[i][len(log_total_word_count)]==0 and s<0:\n",
    "        th += 1\n",
    "print(\"Iterations:\",iterations)\n",
    "print(\"Accuracy:\",(ts+th)/tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e4242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
